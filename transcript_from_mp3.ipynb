{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in /opt/miniconda3/envs/office/lib/python3.9/site-packages (3.14.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from SpeechRecognition) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pydub in /opt/miniconda3/envs/office/lib/python3.9/site-packages (0.25.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openai-whisper in /opt/miniconda3/envs/office/lib/python3.9/site-packages (20240930)\n",
      "Requirement already satisfied: numba in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from openai-whisper) (0.60.0)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from openai-whisper) (2.0.2)\n",
      "Requirement already satisfied: torch in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from openai-whisper) (2.2.2)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from openai-whisper) (4.67.1)\n",
      "Requirement already satisfied: more-itertools in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from openai-whisper) (10.6.0)\n",
      "Requirement already satisfied: tiktoken in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from openai-whisper) (0.8.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from numba->openai-whisper) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from torch->openai-whisper) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from torch->openai-whisper) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from torch->openai-whisper) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from torch->openai-whisper) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from torch->openai-whisper) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from torch->openai-whisper) (2024.10.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ffmpeg in /opt/miniconda3/envs/office/lib/python3.9/site-packages (1.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install SpeechRecognition \n",
    "%pip install pydub\n",
    "%pip install openai-whisper\n",
    "%pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2\n",
      "  Using cached numpy-1.26.4-cp39-cp39-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp39-cp39-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mediapipe 0.10.18 requires flatbuffers>=2.0, but you have flatbuffers 1.12 which is incompatible.\n",
      "mediapipe 0.10.18 requires protobuf<5,>=4.25.3, but you have protobuf 3.20.3 which is incompatible.\n",
      "tensorflow 2.5.0 requires numpy~=1.19.2, but you have numpy 1.26.4 which is incompatible.\n",
      "tensorflow 2.5.0 requires typing-extensions~=3.7.4, but you have typing-extensions 4.12.2 which is incompatible.\n",
      "tf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge ffmpeg\n",
    "#need to run this for ffmpeg to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtranscribe(audio_file)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 31\u001b[0m transcript \u001b[38;5;241m=\u001b[39m \u001b[43mtranscribe_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(transcript)\n",
      "Cell \u001b[0;32mIn[12], line 27\u001b[0m, in \u001b[0;36mtranscribe_audio\u001b[0;34m(audio_file)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranscribe_audio\u001b[39m(audio_file):\n\u001b[0;32m---> 27\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mwhisper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbase\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtranscribe(audio_file)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/office/lib/python3.9/site-packages/whisper/__init__.py:158\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, device, download_root, in_memory)\u001b[0m\n\u001b[1;32m    155\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m alignment_heads \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_alignment_heads\u001b[49m\u001b[43m(\u001b[49m\u001b[43malignment_heads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/office/lib/python3.9/site-packages/whisper/model.py:282\u001b[0m, in \u001b[0;36mWhisper.set_alignment_heads\u001b[0;34m(self, dump)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_alignment_heads\u001b[39m(\u001b[38;5;28mself\u001b[39m, dump: \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m    279\u001b[0m     array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(\n\u001b[1;32m    280\u001b[0m         gzip\u001b[38;5;241m.\u001b[39mdecompress(base64\u001b[38;5;241m.\u001b[39mb85decode(dump)), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m\n\u001b[1;32m    281\u001b[0m     )\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 282\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims\u001b[38;5;241m.\u001b[39mn_text_layer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims\u001b[38;5;241m.\u001b[39mn_text_head\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_buffer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malignment_heads\u001b[39m\u001b[38;5;124m\"\u001b[39m, mask\u001b[38;5;241m.\u001b[39mto_sparse(), persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import which\n",
    "\n",
    "AudioSegment.converter = which(\"ffmpeg\")\n",
    "AudioSegment.ffprobe = which(\"ffprobe\")\n",
    "\n",
    "\n",
    "# Initialize the recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Specify the path to your MP3 file\n",
    "mp3_file = \"/Users/rgopalam/Desktop/office/audio2.mp3\"\n",
    "\n",
    "# Convert MP3 to WAV\n",
    "from pydub import AudioSegment\n",
    "audio = AudioSegment.from_mp3(mp3_file)\n",
    "wav_file = \"temp_audio.wav\"\n",
    "audio.export(wav_file, format=\"wav\")\n",
    "\n",
    "# Recognize the speech in the audio file\n",
    "import whisper\n",
    "\n",
    "def transcribe_audio(audio_file):\n",
    "    model = whisper.load_model(\"base\")\n",
    "    result = model.transcribe(audio_file)\n",
    "    return result[\"text\"]\n",
    "\n",
    "transcript = transcribe_audio(wav_file)\n",
    "print(transcript)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription:\n",
      "from this now I'm loving my shoes these aren't my shoes I'm buying them so you can do whatever you want to them mate go on get in there  get in there you love the fact that this dog is chewing on these  they're tasty they're shoes how much are these shoes 1,800 bucks I'm getting there guys\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import which\n",
    "from google.cloud import speech\n",
    "\n",
    "# Ensure ffmpeg and ffprobe paths are set\n",
    "AudioSegment.converter = which(\"ffmpeg\")\n",
    "AudioSegment.ffprobe = which(\"ffprobe\")\n",
    "\n",
    "# Set the path to your Google Cloud JSON credentials\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/rgopalam/Desktop/seismic-rarity-427422-p7-ab3b4a8726ef.json\"\n",
    "\n",
    "def get_sample_rate(audio_file):\n",
    "    \"\"\"Get the sample rate of the audio file.\"\"\"\n",
    "    try:\n",
    "        audio = AudioSegment.from_file(audio_file)\n",
    "        return audio.frame_rate\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting sample rate: {e}\")\n",
    "        return None\n",
    "\n",
    "def convert_mp3_to_wav(mp3_file, output_file=\"temp_audio.wav\"):\n",
    "    \"\"\"Convert an MP3 file to WAV format with a single channel (mono).\"\"\"\n",
    "    try:\n",
    "        audio = AudioSegment.from_mp3(mp3_file)\n",
    "        audio = audio.set_channels(1)  # Convert to mono\n",
    "        audio.export(output_file, format=\"wav\")\n",
    "        return output_file\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting MP3 to WAV: {e}\")\n",
    "        return None\n",
    "\n",
    "def transcribe_audio_google(audio_file):\n",
    "    \"\"\"Transcribe audio using Google Cloud Speech-to-Text.\"\"\"\n",
    "    try:\n",
    "        # Initialize the Speech-to-Text client\n",
    "        client = speech.SpeechClient()\n",
    "\n",
    "        # Read the audio file\n",
    "        with open(audio_file, \"rb\") as audio:\n",
    "            audio_content = audio.read()\n",
    "\n",
    "        # Get the sample rate of the WAV file\n",
    "        sample_rate = get_sample_rate(audio_file)\n",
    "        if not sample_rate:\n",
    "            print(\"Could not determine sample rate.\")\n",
    "            return None\n",
    "\n",
    "        # Configure the recognition request\n",
    "        audio_config = speech.RecognitionConfig(\n",
    "            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "            sample_rate_hertz=sample_rate,  # Dynamically match the WAV file's sample rate\n",
    "            language_code=\"en-US\"\n",
    "        )\n",
    "        audio_request = speech.RecognitionAudio(content=audio_content)\n",
    "\n",
    "        # Perform the transcription\n",
    "        response = client.recognize(config=audio_config, audio=audio_request)\n",
    "\n",
    "        # Concatenate all transcriptions into one string\n",
    "        transcript = \" \".join([result.alternatives[0].transcript for result in response.results])\n",
    "        return transcript\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during transcription: {e}\")\n",
    "        return None\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    mp3_file = \"/Users/rgopalam/Desktop/office/audio2.mp3\"\n",
    "    \n",
    "    if not os.path.exists(mp3_file):\n",
    "        print(f\"File not found: {mp3_file}\")\n",
    "    else:\n",
    "        wav_file = convert_mp3_to_wav(mp3_file)\n",
    "        if wav_file:\n",
    "            transcript = transcribe_audio_google(wav_file)\n",
    "            if transcript:\n",
    "                print(\"Transcription:\")\n",
    "                print(transcript)\n",
    "            # Clean up temporary file\n",
    "            os.remove(wav_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "office",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
