{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to quit the video stream.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[swscaler @ 0x111220000] [swscaler @ 0x111230000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x111220000] [swscaler @ 0x111250000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x111220000] [swscaler @ 0x111260000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x111220000] [swscaler @ 0x111270000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x111220000] [swscaler @ 0x111280000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x111220000] [swscaler @ 0x111290000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x111220000] [swscaler @ 0x1112a0000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x111220000] [swscaler @ 0x1112b0000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x111220000] [swscaler @ 0x1112c0000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x111220000] [swscaler @ 0x111230000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x111220000] [swscaler @ 0x111250000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x111220000] [swscaler @ 0x111260000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x111220000] [swscaler @ 0x111270000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x111220000] [swscaler @ 0x111280000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x111220000] [swscaler @ 0x111290000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x111220000] [swscaler @ 0x1112a0000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x111220000] [swscaler @ 0x1112b0000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x111220000] [swscaler @ 0x1112c0000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1208c8000] [swscaler @ 0x1208d8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1208c8000] [swscaler @ 0x1208e8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1208c8000] [swscaler @ 0x1208f8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1208c8000] [swscaler @ 0x120908000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1208c8000] [swscaler @ 0x120918000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1208c8000] [swscaler @ 0x120928000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1208c8000] [swscaler @ 0x120938000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1208c8000] [swscaler @ 0x120948000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1208c8000] [swscaler @ 0x120958000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1208c8000] [swscaler @ 0x120358000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1208c8000] [swscaler @ 0x111220000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1208c8000] [swscaler @ 0x111230000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1208c8000] [swscaler @ 0x111250000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1208c8000] [swscaler @ 0x111260000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1208c8000] [swscaler @ 0x111270000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1208c8000] [swscaler @ 0x111280000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1208c8000] [swscaler @ 0x111290000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1208c8000] [swscaler @ 0x1112a0000] No accelerated colorspace conversion found from yuv420p to rgb24.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Transcript]: 'you' 'and' 'I' 'love' 'crime' 'junkies' 'love' 'love' 'that's' 'like' 'our' 'go-to' 'podcast' 'when' 'we're' 'doing' 'our' 'road' 'trips'\n",
      "[Transcript]: 'you' 'and' 'I' 'love' 'crime' 'junkies' 'love' 'love' 'that's' 'like' 'our' 'go-to' 'podcast' 'when' 'we're' 'doing' 'our' 'road' 'trips' 'we're' 'obsessed'\n",
      "[Transcript]: 'you' 'and' 'I' 'love' 'crime' 'junkies' 'love' 'love' 'that's' 'like' 'our' 'go-to' 'podcast' 'when' 'we're' 'doing' 'our' 'road' 'trips' 'we're' 'obsessed' 'yes'\n",
      "[Transcript]: 'you' 'and' 'I' 'love' 'crime' 'junkies' [Speaker 1] 'love' [Speaker 2] 'love' 'that's' 'like' 'our' 'go-to' 'podcast' 'when' 'we're' 'doing' 'our' 'road' 'trips' 'we're' 'obsessed' [Speaker 1] 'yes' [Speaker 2] 'so' 'true' 'crime' 'is' 'a' 'huge' 'Niche' 'I' 'feel' 'like'\n",
      "[Transcript]: 'you' 'and' 'I' 'love' 'crime' 'junkies' [Speaker 1] 'love' [Speaker 2] 'love' 'that's' 'like' 'our' 'go-to' 'podcast' 'when' 'we're' 'doing' 'our' 'road' 'trips' 'we're' 'obsessed' [Speaker 1] 'yes' [Speaker 2] 'so' 'true' 'crime' 'is' 'a' 'huge' 'Niche' 'I' 'feel' 'like' 'everyone' 'listens' 'to' 'it' 'and' 'if' 'you' 'don't' 'like' 'you' 'hear' 'about' 'it' 'I' 'don't' 'know' 'so' 'with' 'it' 'finally' 'being' 'October' 'and' 'things' 'getting' 'a' 'little' 'spookier' 'I' 'figured'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import cv2\n",
    "import yt_dlp\n",
    "from ffpyplayer.player import MediaPlayer\n",
    "from google.cloud import speech\n",
    "from queue import Queue\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Set Google Cloud credentials\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/anaishadas/Desktop/theoffice/seismic-rarity-427422-p7-ab3b4a8726ef.json\"\n",
    "\n",
    "def transcribe_audio_stream(audio_url, transcription_queue):\n",
    "    \"\"\"Stream audio for transcription using Google Cloud Speech-to-Text.\"\"\"\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    # Use ffmpeg to convert audio stream to raw PCM data\n",
    "    ffmpeg_command = [\n",
    "        \"ffmpeg\", \"-i\", audio_url, \"-f\", \"s16le\", \"-ac\", \"1\", \"-ar\", \"16000\",\n",
    "        \"-loglevel\", \"quiet\", \"pipe:1\"\n",
    "    ]\n",
    "    process = subprocess.Popen(ffmpeg_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "    speaker_diarization_config = speech.SpeakerDiarizationConfig(\n",
    "        enable_speaker_diarization=True,\n",
    "        min_speaker_count=2,  # Set minimum number of speakers\n",
    "        max_speaker_count=2,  # Adjust max speakers based on expected number of speakers\n",
    "    )\n",
    "\n",
    "    streaming_config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=16000,\n",
    "        language_code=\"en-US\",\n",
    "        diarization_config=speaker_diarization_config,\n",
    "    )\n",
    "    streaming_request = speech.StreamingRecognitionConfig(config=streaming_config, interim_results=True)\n",
    "\n",
    "    def audio_generator():\n",
    "        while True:\n",
    "            data = process.stdout.read(4096)\n",
    "            if not data:\n",
    "                break\n",
    "            yield data\n",
    "\n",
    "    requests = (speech.StreamingRecognizeRequest(audio_content=chunk) for chunk in audio_generator())\n",
    "    responses = client.streaming_recognize(config=streaming_request, requests=requests)\n",
    "\n",
    "    # The transcript within each result is separate and sequential per result.\n",
    "    # However, the words list within an alternative includes all the words\n",
    "    # from all the results thus far. Thus, to get all the words with speaker\n",
    "    # tags, you only have to take the words list from the last result\n",
    "    try:\n",
    "        current_speaker_tag = None  # Variable to track the current speaker\n",
    "        final_transcription = []  # List to accumulate words in the final transcription\n",
    "\n",
    "        for response in responses:\n",
    "            result = response.results[-1]  # Get the latest result\n",
    "            words_info = result.alternatives[0].words  # Extract words info\n",
    "\n",
    "            # Process each word and track speaker change\n",
    "            for word_info in words_info:\n",
    "                # If speaker changes, append the previous speaker's transcription\n",
    "                if current_speaker_tag != word_info.speaker_tag:\n",
    "                    if current_speaker_tag is not None:\n",
    "                        final_transcription.append(f\"[Speaker {current_speaker_tag}]\")  # Mark the change\n",
    "                    current_speaker_tag = word_info.speaker_tag  # Update the current speaker\n",
    "\n",
    "                final_transcription.append(f\"'{word_info.word}'\")  # Add the word to the transcription\n",
    "            \n",
    "\n",
    "            # Handle final transcriptions\n",
    "            if result.is_final:\n",
    "                transcription = \" \".join(final_transcription)\n",
    "                timestamp = time.time()  # Record when the transcription was generated\n",
    "                transcription_queue.put((timestamp, transcription))\n",
    "                final_transcription = []  # Reset for the next chunk of final transcription\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Transcription error: {e}\")\n",
    "    finally:\n",
    "        process.terminate()  # Ensure process is terminated after handling exceptions\n",
    "\n",
    "def play_video_with_audio_and_transcription(video_url):\n",
    "    \"\"\"Play video with synchronized audio and perform real-time transcription.\"\"\"\n",
    "    # yt-dlp options to fetch the best video URL\n",
    "    ydl_opts = {\n",
    "        \"format\": \"best\",            # Fetch the best video + audio format\n",
    "        \"quiet\": True,               # Suppress output\n",
    "        \"no_warnings\": True          # Suppress warnings\n",
    "    }\n",
    "\n",
    "    # Fetch video info and get the stream URL\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(video_url, download=False)\n",
    "        video_stream_url = info[\"url\"]\n",
    "\n",
    "    # Fetch audio URL\n",
    "    audio_opts = {\"format\": \"bestaudio/best\", \"quiet\": True, \"no_warnings\": True}\n",
    "    with yt_dlp.YoutubeDL(audio_opts) as ydl:\n",
    "        audio_info = ydl.extract_info(video_url, download=False)\n",
    "        audio_stream_url = audio_info[\"url\"]\n",
    "\n",
    "    # Initialize OpenCV video capture\n",
    "    cap = cv2.VideoCapture(video_stream_url)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Cannot open video stream.\")\n",
    "        return\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)  # Get frame rate\n",
    "    frame_delay = int(1000 / fps)  # Delay between frames in milliseconds\n",
    "\n",
    "    # Initialize ffpyplayer for audio\n",
    "    player = MediaPlayer(video_stream_url)\n",
    "\n",
    "    # Queue for synchronized transcription\n",
    "    transcription_queue = Queue()\n",
    "\n",
    "    # Start transcription in a background thread\n",
    "    transcription_thread = threading.Thread(\n",
    "        target=transcribe_audio_stream, args=(audio_stream_url, transcription_queue)\n",
    "    )\n",
    "    transcription_thread.start()\n",
    "\n",
    "    print(\"Press 'q' to quit the video stream.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"End of stream or cannot fetch frame.\")\n",
    "            break\n",
    "\n",
    "        # Display video frame\n",
    "        cv2.imshow('YouTube Video Stream', frame)\n",
    "\n",
    "        # Play audio synchronously\n",
    "        audio_frame, val = player.get_frame()\n",
    "        if val != 'eof' and audio_frame:\n",
    "            _, timestamp = audio_frame\n",
    "\n",
    "            # Synchronize and display transcription\n",
    "            while not transcription_queue.empty():\n",
    "                transcription_time, transcription = transcription_queue.queue[0]\n",
    "                if transcription_time <= time.time():  # Check if it's time to display the transcription\n",
    "                    print(\"[Transcript]:\", transcription)\n",
    "                    transcription_queue.get()\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        # Exit on pressing 'q'\n",
    "        if cv2.waitKey(frame_delay) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    player.close_player()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Wait for transcription thread to completeq\n",
    "    transcription_thread.join()\n",
    "\n",
    "# Replace with your YouTube video URL\n",
    "youtube_url = \"https://www.youtube.com/watch?v=96Y6mc3C1Bg\"  # Example video\n",
    "play_video_with_audio_and_transcription(youtube_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'player' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m player\u001b[39m.\u001b[39mclose_player()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'player' is not defined"
     ]
    }
   ],
   "source": [
    "player.close_player()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydl_opts = {\n",
    "        \"format\": \"best\",            # Fetch the best video + audio format\n",
    "        \"quiet\": True,               # Suppress output\n",
    "        \"no_warnings\": True          # Suppress warnings\n",
    "    }\n",
    "\n",
    "video_url = \"https://www.youtube.com/watch?v=96Y6mc3C1Bg\"\n",
    "\n",
    "\n",
    "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(video_url, download=False)\n",
    "        video_stream_url = info[\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_opts = {\"format\": \"bestaudio/best\", \"quiet\": True, \"no_warnings\": True}\n",
    "with yt_dlp.YoutubeDL(audio_opts) as ydl:\n",
    "    audio_info = ydl.extract_info(video_url, download=False)\n",
    "    audio_stream_url = audio_info[\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://rr5---sn-o097znzr.googlevideo.com/videoplayback?expire=1741531518&ei=HlXNZ42PG7qQsfIPtsCYMQ&ip=2601%3A644%3A9081%3A6680%3A41c8%3A9ff5%3A7880%3A2892&id=o-AHNyhy0DGkwnek4nhUUjwUGg8ao6Q27MtkHGlQBxteXg&itag=251&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&met=1741509918%2C&mh=KN&mm=31%2C26&mn=sn-o097znzr%2Csn-a5mekndz&ms=au%2Conr&mv=m&mvi=5&pl=46&rms=au%2Cau&initcwndbps=4897500&bui=AUWDL3wFd5WMGGfh4ZTjHsR50Tf6-fLND7dijFX11tILrfktZ9Tv04J_l9REGuOjUAWeSY-A41Mi5PIj&vprv=1&svpuc=1&mime=audio%2Fwebm&ns=FeHJZbs1tv_HL3haTRxZLuoQ&rqh=1&gir=yes&clen=75946061&dur=5104.141&lmt=1729252675319032&mt=1741509436&fvip=2&keepalive=yes&lmw=1&fexp=51326932%2C51410171%2C51411872&c=TVHTML5&sefc=1&txp=5532434&n=156yqHv0n90FWw&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cbui%2Cvprv%2Csvpuc%2Cmime%2Cns%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRgIhAP1Xo5v1wV1qzjFCPH71iaPey6zfyKbVF7wsr3d7_rJTAiEAsg7BJ9RO-eyr0UR0FldBGzmDAnrPUvO1_P_-a9X9VeM%3D&lsparams=met%2Cmh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Crms%2Cinitcwndbps&lsig=AFVRHeAwRgIhAL9U7b5_KfvRImAIftRq6r1sLxXjOqTy9QWBVmCokDwtAiEAmMxIhCWw77iThRTbL1mBbBem5BO101BSbKxQcBJsVWo%3D\n"
     ]
    }
   ],
   "source": [
    "print(audio_stream_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ffpyplayer\n",
      "  Downloading ffpyplayer-4.5.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Downloading ffpyplayer-4.5.2-cp39-cp39-macosx_11_0_arm64.whl (18.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ffpyplayer\n",
      "Successfully installed ffpyplayer-4.5.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ffpyplayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google.cloud import speech\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediapipe_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
