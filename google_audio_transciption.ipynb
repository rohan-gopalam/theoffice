{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-23:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/mediapipe_env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/mediapipe_env/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/opt/anaconda3/envs/mediapipe_env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/lj/b8t255bd50s9w1w_tyqwcx140000gn/T/ipykernel_45922/3476782450.py\", line 16, in transcribe_audio_stream\n",
      "  File \"/opt/anaconda3/envs/mediapipe_env/lib/python3.9/site-packages/google/cloud/speech_v1/services/speech/client.py\", line 672, in __init__\n",
      "    self._transport = transport_init(\n",
      "  File \"/opt/anaconda3/envs/mediapipe_env/lib/python3.9/site-packages/google/cloud/speech_v1/services/speech/transports/grpc.py\", line 235, in __init__\n",
      "    super().__init__(\n",
      "  File \"/opt/anaconda3/envs/mediapipe_env/lib/python3.9/site-packages/google/cloud/speech_v1/services/speech/transports/base.py\", line 100, in __init__\n",
      "    credentials, _ = google.auth.default(\n",
      "  File \"/opt/anaconda3/envs/mediapipe_env/lib/python3.9/site-packages/google/auth/_default.py\", line 663, in default\n",
      "    credentials, project_id = checker()\n",
      "  File \"/opt/anaconda3/envs/mediapipe_env/lib/python3.9/site-packages/google/auth/_default.py\", line 656, in <lambda>\n",
      "    lambda: _get_explicit_environ_credentials(quota_project_id=quota_project_id),\n",
      "  File \"/opt/anaconda3/envs/mediapipe_env/lib/python3.9/site-packages/google/auth/_default.py\", line 271, in _get_explicit_environ_credentials\n",
      "    credentials, project_id = load_credentials_from_file(\n",
      "  File \"/opt/anaconda3/envs/mediapipe_env/lib/python3.9/site-packages/google/auth/_default.py\", line 114, in load_credentials_from_file\n",
      "    raise exceptions.DefaultCredentialsError(\n",
      "google.auth.exceptions.DefaultCredentialsError: File /Users/rgopalam/Desktop/seismic-rarity-427422-p7-ab3b4a8726ef.json was not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to quit the video stream.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 16:38:39.143 python[45922:6064922] +[IMKClient subclass]: chose IMKClient_Legacy\n",
      "2025-01-22 16:38:39.143 python[45922:6064922] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x108630000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x108640000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x108650000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x108660000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x108670000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x108680000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x108690000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x1086a0000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x1086b0000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x1086c0000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x1086d0000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x108448000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x108458000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x108468000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x108478000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x108488000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x108498000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x1084a8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x1084b8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x1084c8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x1084d8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x1084e8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x1111a8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x1111b8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x1111c8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x1111d8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x1111e8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x1111f8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x111208000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x111218000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x111228000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x111238000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x111248000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x108448000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x108458000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x108468000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x108478000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x108488000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x108498000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x150928000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x150938000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x150948000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x1084a8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x108620000] [swscaler @ 0x1084b8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import cv2\n",
    "import yt_dlp\n",
    "from ffpyplayer.player import MediaPlayer\n",
    "from google.cloud import speech\n",
    "from queue import Queue\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Set Google Cloud credentials\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/rgopalam/Desktop/seismic-rarity-427422-p7-ab3b4a8726ef.json\"\n",
    "\n",
    "def transcribe_audio_stream(audio_url, transcription_queue):\n",
    "    \"\"\"Stream audio for transcription using Google Cloud Speech-to-Text.\"\"\"\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    # Use ffmpeg to convert audio stream to raw PCM data\n",
    "    ffmpeg_command = [\n",
    "        \"ffmpeg\", \"-i\", audio_url, \"-f\", \"s16le\", \"-ac\", \"1\", \"-ar\", \"16000\",\n",
    "        \"-loglevel\", \"quiet\", \"pipe:1\"\n",
    "    ]\n",
    "    process = subprocess.Popen(ffmpeg_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "    streaming_config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=16000,\n",
    "        language_code=\"en-US\",\n",
    "    )\n",
    "    streaming_request = speech.StreamingRecognitionConfig(config=streaming_config, interim_results=True)\n",
    "\n",
    "    def audio_generator():\n",
    "        while True:\n",
    "            data = process.stdout.read(4096)\n",
    "            if not data:\n",
    "                break\n",
    "            yield data\n",
    "\n",
    "    requests = (speech.StreamingRecognizeRequest(audio_content=chunk) for chunk in audio_generator())\n",
    "    responses = client.streaming_recognize(config=streaming_request, requests=requests)\n",
    "\n",
    "    try:\n",
    "        for response in responses:\n",
    "            for result in response.results:\n",
    "                if result.is_final:\n",
    "                    transcription = result.alternatives[0].transcript\n",
    "                    timestamp = time.time()  # Record when the transcription was generated\n",
    "                    transcription_queue.put((timestamp, transcription))\n",
    "    except Exception as e:\n",
    "        print(f\"Transcription error: {e}\")\n",
    "    finally:\n",
    "        process.terminate()\n",
    "\n",
    "def play_video_with_audio_and_transcription(video_url):\n",
    "    \"\"\"Play video with synchronized audio and perform real-time transcription.\"\"\"\n",
    "    # yt-dlp options to fetch the best video URL\n",
    "    ydl_opts = {\n",
    "        \"format\": \"best\",            # Fetch the best video + audio format\n",
    "        \"quiet\": True,               # Suppress output\n",
    "        \"no_warnings\": True          # Suppress warnings\n",
    "    }\n",
    "\n",
    "    # Fetch video info and get the stream URL\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(video_url, download=False)\n",
    "        video_stream_url = info[\"url\"]\n",
    "\n",
    "    # Fetch audio URL\n",
    "    audio_opts = {\"format\": \"bestaudio/best\", \"quiet\": True, \"no_warnings\": True}\n",
    "    with yt_dlp.YoutubeDL(audio_opts) as ydl:\n",
    "        audio_info = ydl.extract_info(video_url, download=False)\n",
    "        audio_stream_url = audio_info[\"url\"]\n",
    "\n",
    "    # Initialize OpenCV video capture\n",
    "    cap = cv2.VideoCapture(video_stream_url)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Cannot open video stream.\")\n",
    "        return\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)  # Get frame rate\n",
    "    frame_delay = int(1000 / fps)  # Delay between frames in milliseconds\n",
    "\n",
    "    # Initialize ffpyplayer for audio\n",
    "    player = MediaPlayer(video_stream_url)\n",
    "\n",
    "    # Queue for synchronized transcription\n",
    "    transcription_queue = Queue()\n",
    "\n",
    "    # Start transcription in a background thread\n",
    "    transcription_thread = threading.Thread(\n",
    "        target=transcribe_audio_stream, args=(audio_stream_url, transcription_queue)\n",
    "    )\n",
    "    transcription_thread.start()\n",
    "\n",
    "    print(\"Press 'q' to quit the video stream.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"End of stream or cannot fetch frame.\")\n",
    "            break\n",
    "\n",
    "        # Display video frame\n",
    "        cv2.imshow('YouTube Video Stream', frame)\n",
    "\n",
    "        # Play audio synchronously\n",
    "        audio_frame, val = player.get_frame()\n",
    "        if val != 'eof' and audio_frame:\n",
    "            _, timestamp = audio_frame\n",
    "\n",
    "            # Synchronize and display transcription\n",
    "            while not transcription_queue.empty():\n",
    "                transcription_time, transcription = transcription_queue.queue[0]\n",
    "                if transcription_time <= time.time():  # Check if it's time to display the transcription\n",
    "                    print(\"[Transcript]:\", transcription)\n",
    "                    transcription_queue.get()\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        # Exit on pressing 'q'\n",
    "        if cv2.waitKey(frame_delay) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    player.close_player()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Wait for transcription thread to complete\n",
    "    transcription_thread.join()\n",
    "\n",
    "# Replace with your YouTube video URL\n",
    "youtube_url = \"https://www.youtube.com/watch?v=96Y6mc3C1Bg\"  # Example video\n",
    "play_video_with_audio_and_transcription(youtube_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ffpyplayer\n",
      "  Downloading ffpyplayer-4.5.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Downloading ffpyplayer-4.5.2-cp39-cp39-macosx_11_0_arm64.whl (18.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ffpyplayer\n",
      "Successfully installed ffpyplayer-4.5.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ffpyplayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediapipe_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
