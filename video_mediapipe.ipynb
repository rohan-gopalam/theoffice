{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded to detector.tflite\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\"\n",
    "output_path = \"detector.tflite\"\n",
    "\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Downloaded to {output_path}\")\n",
    "else:\n",
    "    print(f\"Failed to download. HTTP Status Code: {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in /opt/miniconda3/envs/office/lib/python3.9/site-packages (0.10.20)\n",
      "Requirement already satisfied: absl-py in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from mediapipe) (0.15.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from mediapipe) (24.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from mediapipe) (25.1.21)\n",
      "Requirement already satisfied: jax in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from mediapipe) (0.4.30)\n",
      "Requirement already satisfied: jaxlib in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from mediapipe) (0.4.30)\n",
      "Requirement already satisfied: matplotlib in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from mediapipe) (3.6.3)\n",
      "Requirement already satisfied: numpy<2 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from mediapipe) (1.21.0)\n",
      "Requirement already satisfied: opencv-contrib-python in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from mediapipe) (4.10.0.84)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from mediapipe) (4.25.5)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from mediapipe) (0.5.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from mediapipe) (0.2.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: six in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from absl-py->mediapipe) (1.15.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from jax->mediapipe) (0.3.2)\n",
      "Collecting numpy<2 (from mediapipe)\n",
      "  Using cached numpy-1.26.4-cp39-cp39-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: opt-einsum in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from jax->mediapipe) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.9 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from jax->mediapipe) (1.13.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from jax->mediapipe) (8.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from matplotlib->mediapipe) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from matplotlib->mediapipe) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from matplotlib->mediapipe) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from matplotlib->mediapipe) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from matplotlib->mediapipe) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from matplotlib->mediapipe) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/miniconda3/envs/office/lib/python3.9/site-packages (from importlib-metadata>=4.6->jax->mediapipe) (3.21.0)\n",
      "Using cached numpy-1.26.4-cp39-cp39-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.0\n",
      "    Uninstalling numpy-1.21.0:\n",
      "      Successfully uninstalled numpy-1.21.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.10.0 requires protobuf<4,>=3.12, but you have protobuf 4.25.5 which is incompatible.\n",
      "tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.25.5 which is incompatible.\n",
      "tensorflow 2.5.0 requires flatbuffers~=1.12.0, but you have flatbuffers 25.1.21 which is incompatible.\n",
      "tensorflow 2.5.0 requires grpcio~=1.34.0, but you have grpcio 1.69.0 which is incompatible.\n",
      "tensorflow 2.5.0 requires numpy~=1.19.2, but you have numpy 1.26.4 which is incompatible.\n",
      "tensorflow 2.5.0 requires typing-extensions~=3.7.4, but you have typing-extensions 4.12.2 which is incompatible.\n",
      "tf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf<3.21.0,>=3.20.0\n",
      "  Using cached protobuf-3.20.3-cp39-cp39-macosx_10_9_x86_64.whl.metadata (679 bytes)\n",
      "Using cached protobuf-3.20.3-cp39-cp39-macosx_10_9_x86_64.whl (982 kB)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.5\n",
      "    Uninstalling protobuf-4.25.5:\n",
      "      Successfully uninstalled protobuf-4.25.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "grpcio-status 1.69.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "mediapipe 0.10.20 requires protobuf<5,>=4.25.3, but you have protobuf 3.20.3 which is incompatible.\n",
      "tensorflow 2.5.0 requires flatbuffers~=1.12.0, but you have flatbuffers 25.1.21 which is incompatible.\n",
      "tensorflow 2.5.0 requires grpcio~=1.34.0, but you have grpcio 1.69.0 which is incompatible.\n",
      "tensorflow 2.5.0 requires numpy~=1.19.2, but you have numpy 1.26.4 which is incompatible.\n",
      "tensorflow 2.5.0 requires typing-extensions~=3.7.4, but you have typing-extensions 4.12.2 which is incompatible.\n",
      "tf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed protobuf-3.20.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"protobuf>=3.20.0,<3.21.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'typeDict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/opt/miniconda3/envs/office/lib/python3.9/site-packages/numpy/__init__.py:333\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemoved in NumPy 1.25.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTester was removed in NumPy 1.25.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'typeDict'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/office/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:511: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  np.object,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'object'.\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Function to fetch the direct video URL using yt-dlp\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/office/lib/python3.9/site-packages/mediapipe/__init__.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msolutions\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msolutions\u001b[39;00m \n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtasks\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m framework\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m gpu\n",
      "File \u001b[0;32m/opt/miniconda3/envs/office/lib/python3.9/site-packages/mediapipe/tasks/python/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The MediaPipe Authors.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"MediaPipe Tasks API.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m components\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core\n",
      "File \u001b[0;32m/opt/miniconda3/envs/office/lib/python3.9/site-packages/mediapipe/tasks/python/audio/__init__.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"MediaPipe Tasks Audio API.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio_classifier\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio_embedder\u001b[39;00m\n\u001b[1;32m     21\u001b[0m AudioClassifier \u001b[38;5;241m=\u001b[39m audio_classifier\u001b[38;5;241m.\u001b[39mAudioClassifier\n",
      "File \u001b[0;32m/opt/miniconda3/envs/office/lib/python3.9/site-packages/mediapipe/tasks/python/audio/audio_classifier.py:26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocessors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classifier_options_pb2\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio_task_running_mode \u001b[38;5;28;01mas\u001b[39;00m running_mode_module\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_audio_task_api\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontainers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio_data \u001b[38;5;28;01mas\u001b[39;00m audio_data_module\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontainers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_result \u001b[38;5;28;01mas\u001b[39;00m classification_result_module\n",
      "File \u001b[0;32m/opt/miniconda3/envs/office/lib/python3.9/site-packages/mediapipe/tasks/python/audio/core/base_audio_task_api.py:25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio_record\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio_task_running_mode \u001b[38;5;28;01mas\u001b[39;00m running_mode_module\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptional_dependencies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m doc_controls\n\u001b[1;32m     27\u001b[0m _TaskRunner \u001b[38;5;241m=\u001b[39m task_runner_module\u001b[38;5;241m.\u001b[39mTaskRunner\n\u001b[1;32m     28\u001b[0m _Packet \u001b[38;5;241m=\u001b[39m packet_module\u001b[38;5;241m.\u001b[39mPacket\n",
      "File \u001b[0;32m/opt/miniconda3/envs/office/lib/python3.9/site-packages/mediapipe/tasks/python/core/optional_dependencies.py:20\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# TensorFlow isn't a dependency of mediapipe pip package. It's only\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# required in the API docgen pipeline so we'll ignore it if tensorflow is not\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# installed.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m doc_controls\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m   \u001b[38;5;66;03m# Replace the real doc_controls.do_not_generate_docs with an no-op\u001b[39;00m\n\u001b[1;32m     23\u001b[0m   doc_controls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/office/lib/python3.9/site-packages/tensorflow/__init__.py:41\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_six\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/office/lib/python3.9/site-packages/tensorflow/python/__init__.py:46\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "File \u001b[0;32m/opt/miniconda3/envs/office/lib/python3.9/site-packages/tensorflow/python/data/__init__.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AUTOTUNE\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "File \u001b[0;32m/opt/miniconda3/envs/office/lib/python3.9/site-packages/tensorflow/python/data/experimental/__init__.py:99\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m service\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_ragged_batch\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_sparse_batch\n",
      "File \u001b[0;32m/opt/miniconda3/envs/office/lib/python3.9/site-packages/tensorflow/python/data/experimental/service/__init__.py:140\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m division\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_dataset_id\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_dataset\n",
      "File \u001b[0;32m/opt/miniconda3/envs/office/lib/python3.9/site-packages/tensorflow/python/data/experimental/ops/data_service_ops.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compression_ops\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute_options\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoShardPolicy\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute_options\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExternalStatePolicy\n",
      "File \u001b[0;32m/opt/miniconda3/envs/office/lib/python3.9/site-packages/tensorflow/python/data/experimental/ops/compression_ops.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m division\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structure\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_experimental_dataset_ops \u001b[38;5;28;01mas\u001b[39;00m ged_ops\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompress\u001b[39m(element):\n",
      "File \u001b[0;32m/opt/miniconda3/envs/office/lib/python3.9/site-packages/tensorflow/python/data/util/structure.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwrapt\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nest\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m composite_tensor\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n",
      "File \u001b[0;32m/opt/miniconda3/envs/office/lib/python3.9/site-packages/tensorflow/python/data/util/nest.py:40\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_six\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse_tensor \u001b[38;5;28;01mas\u001b[39;00m _sparse_tensor\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nest\n",
      "File \u001b[0;32m/opt/miniconda3/envs/office/lib/python3.9/site-packages/tensorflow/python/framework/sparse_tensor.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m composite_tensor\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constant_op\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n",
      "File \u001b[0;32m/opt/miniconda3/envs/office/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types_pb2\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m execute\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m op_callbacks\n",
      "File \u001b[0;32m/opt/miniconda3/envs/office/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tfe\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n",
      "File \u001b[0;32m/opt/miniconda3/envs/office/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:511\u001b[0m\n\u001b[1;32m    480\u001b[0m     _NP_TO_TF[pdt] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m    481\u001b[0m         _NP_TO_TF[dt] \u001b[38;5;28;01mfor\u001b[39;00m dt \u001b[38;5;129;01min\u001b[39;00m _NP_TO_TF \u001b[38;5;28;01mif\u001b[39;00m dt \u001b[38;5;241m==\u001b[39m pdt()\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    484\u001b[0m TF_VALUE_DTYPES \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(_NP_TO_TF\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    487\u001b[0m _TF_TO_NP \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    488\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_HALF:\n\u001b[1;32m    489\u001b[0m         np\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[1;32m    490\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_FLOAT:\n\u001b[1;32m    491\u001b[0m         np\u001b[38;5;241m.\u001b[39mfloat32,\n\u001b[1;32m    492\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_DOUBLE:\n\u001b[1;32m    493\u001b[0m         np\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[1;32m    494\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_INT32:\n\u001b[1;32m    495\u001b[0m         np\u001b[38;5;241m.\u001b[39mint32,\n\u001b[1;32m    496\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT8:\n\u001b[1;32m    497\u001b[0m         np\u001b[38;5;241m.\u001b[39muint8,\n\u001b[1;32m    498\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT16:\n\u001b[1;32m    499\u001b[0m         np\u001b[38;5;241m.\u001b[39muint16,\n\u001b[1;32m    500\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT32:\n\u001b[1;32m    501\u001b[0m         np\u001b[38;5;241m.\u001b[39muint32,\n\u001b[1;32m    502\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT64:\n\u001b[1;32m    503\u001b[0m         np\u001b[38;5;241m.\u001b[39muint64,\n\u001b[1;32m    504\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_INT16:\n\u001b[1;32m    505\u001b[0m         np\u001b[38;5;241m.\u001b[39mint16,\n\u001b[1;32m    506\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_INT8:\n\u001b[1;32m    507\u001b[0m         np\u001b[38;5;241m.\u001b[39mint8,\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;66;03m# NOTE(touts): For strings we use np.object as it supports variable length\u001b[39;00m\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;66;03m# strings.\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_STRING:\n\u001b[0;32m--> 511\u001b[0m         \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobject\u001b[49m,\n\u001b[1;32m    512\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_COMPLEX64:\n\u001b[1;32m    513\u001b[0m         np\u001b[38;5;241m.\u001b[39mcomplex64,\n\u001b[1;32m    514\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_COMPLEX128:\n\u001b[1;32m    515\u001b[0m         np\u001b[38;5;241m.\u001b[39mcomplex128,\n\u001b[1;32m    516\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_INT64:\n\u001b[1;32m    517\u001b[0m         np\u001b[38;5;241m.\u001b[39mint64,\n\u001b[1;32m    518\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_BOOL:\n\u001b[1;32m    519\u001b[0m         np\u001b[38;5;241m.\u001b[39mbool_,\n\u001b[1;32m    520\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QINT8:\n\u001b[1;32m    521\u001b[0m         _np_qint8,\n\u001b[1;32m    522\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QUINT8:\n\u001b[1;32m    523\u001b[0m         _np_quint8,\n\u001b[1;32m    524\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QINT16:\n\u001b[1;32m    525\u001b[0m         _np_qint16,\n\u001b[1;32m    526\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QUINT16:\n\u001b[1;32m    527\u001b[0m         _np_quint16,\n\u001b[1;32m    528\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QINT32:\n\u001b[1;32m    529\u001b[0m         _np_qint32,\n\u001b[1;32m    530\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_BFLOAT16:\n\u001b[1;32m    531\u001b[0m         _np_bfloat16,\n\u001b[1;32m    532\u001b[0m \n\u001b[1;32m    533\u001b[0m     \u001b[38;5;66;03m# Ref types\u001b[39;00m\n\u001b[1;32m    534\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_HALF_REF:\n\u001b[1;32m    535\u001b[0m         np\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[1;32m    536\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_FLOAT_REF:\n\u001b[1;32m    537\u001b[0m         np\u001b[38;5;241m.\u001b[39mfloat32,\n\u001b[1;32m    538\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_DOUBLE_REF:\n\u001b[1;32m    539\u001b[0m         np\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[1;32m    540\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_INT32_REF:\n\u001b[1;32m    541\u001b[0m         np\u001b[38;5;241m.\u001b[39mint32,\n\u001b[1;32m    542\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT32_REF:\n\u001b[1;32m    543\u001b[0m         np\u001b[38;5;241m.\u001b[39muint32,\n\u001b[1;32m    544\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT8_REF:\n\u001b[1;32m    545\u001b[0m         np\u001b[38;5;241m.\u001b[39muint8,\n\u001b[1;32m    546\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT16_REF:\n\u001b[1;32m    547\u001b[0m         np\u001b[38;5;241m.\u001b[39muint16,\n\u001b[1;32m    548\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_INT16_REF:\n\u001b[1;32m    549\u001b[0m         np\u001b[38;5;241m.\u001b[39mint16,\n\u001b[1;32m    550\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_INT8_REF:\n\u001b[1;32m    551\u001b[0m         np\u001b[38;5;241m.\u001b[39mint8,\n\u001b[1;32m    552\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_STRING_REF:\n\u001b[1;32m    553\u001b[0m         np\u001b[38;5;241m.\u001b[39mobject,\n\u001b[1;32m    554\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_COMPLEX64_REF:\n\u001b[1;32m    555\u001b[0m         np\u001b[38;5;241m.\u001b[39mcomplex64,\n\u001b[1;32m    556\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_COMPLEX128_REF:\n\u001b[1;32m    557\u001b[0m         np\u001b[38;5;241m.\u001b[39mcomplex128,\n\u001b[1;32m    558\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_INT64_REF:\n\u001b[1;32m    559\u001b[0m         np\u001b[38;5;241m.\u001b[39mint64,\n\u001b[1;32m    560\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT64_REF:\n\u001b[1;32m    561\u001b[0m         np\u001b[38;5;241m.\u001b[39muint64,\n\u001b[1;32m    562\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_BOOL_REF:\n\u001b[1;32m    563\u001b[0m         np\u001b[38;5;241m.\u001b[39mbool,\n\u001b[1;32m    564\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QINT8_REF:\n\u001b[1;32m    565\u001b[0m         _np_qint8,\n\u001b[1;32m    566\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QUINT8_REF:\n\u001b[1;32m    567\u001b[0m         _np_quint8,\n\u001b[1;32m    568\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QINT16_REF:\n\u001b[1;32m    569\u001b[0m         _np_qint16,\n\u001b[1;32m    570\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QUINT16_REF:\n\u001b[1;32m    571\u001b[0m         _np_quint16,\n\u001b[1;32m    572\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QINT32_REF:\n\u001b[1;32m    573\u001b[0m         _np_qint32,\n\u001b[1;32m    574\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_BFLOAT16_REF:\n\u001b[1;32m    575\u001b[0m         _np_bfloat16,\n\u001b[1;32m    576\u001b[0m }\n\u001b[1;32m    578\u001b[0m _QUANTIZED_DTYPES_NO_REF \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m([qint8, quint8, qint16, quint16, qint32])\n\u001b[1;32m    579\u001b[0m _QUANTIZED_DTYPES_REF \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m(\n\u001b[1;32m    580\u001b[0m     [qint8_ref, quint8_ref, qint16_ref, quint16_ref, qint32_ref])\n",
      "File \u001b[0;32m/opt/miniconda3/envs/office/lib/python3.9/site-packages/numpy/__init__.py:324\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    319\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'object'.\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "# Function to fetch the direct video URL using yt-dlp\n",
    "def get_video_url(youtube_url):\n",
    "    ydl_opts = {\n",
    "        'quiet': True,\n",
    "        'format': 'best[ext=mp4]'\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(youtube_url, download=False)\n",
    "        return info['url']\n",
    "\n",
    "# Initialize MediaPipe solutions\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize Face Detection and Pose Detection\n",
    "face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.9)\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.8)\n",
    "\n",
    "profiles = {}\n",
    "\n",
    "# Function to assign or update ID based on face embedding and spatial proximity\n",
    "def assign_id(embedding, bbox, profiles, threshold=0.6, spatial_threshold=50):\n",
    "    best_match_id = None\n",
    "    best_similarity = float(\"inf\")\n",
    "    best_distance = float(\"inf\")\n",
    "\n",
    "    bbox_center = ((bbox[0] + bbox[2] / 2), (bbox[1] + bbox[3] / 2))\n",
    "\n",
    "    for profile_id, profile in profiles.items():\n",
    "        # Compare embedding similarity\n",
    "        similarity = np.linalg.norm(np.array(profile['face_embedding']) - np.array(embedding))\n",
    "        # Compare spatial proximity\n",
    "        profile_bbox = profile[\"bbox\"]\n",
    "        profile_center = ((profile_bbox[0] + profile_bbox[2] / 2), (profile_bbox[1] + profile_bbox[3] / 2))\n",
    "        spatial_distance = euclidean(profile_center, bbox_center)\n",
    "\n",
    "        # Find the best match\n",
    "        if similarity < threshold and spatial_distance < spatial_threshold:\n",
    "            if similarity < best_similarity or (similarity == best_similarity and spatial_distance < best_distance):\n",
    "                best_match_id = profile_id\n",
    "                best_similarity = similarity\n",
    "                best_distance = spatial_distance\n",
    "\n",
    "    if best_match_id is not None:\n",
    "        # Update the matched profile\n",
    "        profiles[best_match_id][\"bbox\"] = bbox\n",
    "        profiles[best_match_id][\"last_seen\"] = frame_count\n",
    "        return best_match_id\n",
    "    else:\n",
    "        # Create a new profile\n",
    "        new_id = len(profiles) + 1\n",
    "        profiles[new_id] = {\"face_embedding\": embedding, \"bbox\": bbox, \"last_seen\": frame_count}\n",
    "        return new_id\n",
    "\n",
    "\n",
    "# YouTube video URL\n",
    "youtube_url = \"https://www.youtube.com/watch?v=9D0WmzB5ovY\"  # Replace with your video URL\n",
    "\n",
    "# Process a YouTube video\n",
    "youtube_url = \"https://www.youtube.com/watch?v=96Y6mc3C1Bg\"  # Replace with your URL\n",
    "video_url = get_video_url(youtube_url)\n",
    "print(\"Video URL:\", video_url)\n",
    "\n",
    "cap = cv2.VideoCapture(video_url)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open the YouTube video stream.\")\n",
    "else:\n",
    "    print(\"Processing YouTube video. Press 'q' to quit.\")\n",
    "\n",
    "\n",
    "    # Specify the start time (in seconds)\n",
    "    start_time = 320  # Start the video at 30 seconds\n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC, start_time * 1000)  # Jump to the start time\n",
    "\n",
    "\n",
    "    # Adjustable frame rate (delay in milliseconds)\n",
    "    frame_delay_ms = 100  # Adjust this value to control the frame rate\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"End of video or error reading the video stream.\")\n",
    "            break\n",
    "\n",
    "        # Skip frames for efficiency\n",
    "        if frame_count % 5 != 0:\n",
    "            frame_count += 1\n",
    "            continue\n",
    "\n",
    "        # Validate frame dimensions\n",
    "        if frame is None or frame.shape[0] == 0 or frame.shape[1] == 0:\n",
    "            print(f\"Skipped frame {frame_count}: invalid dimensions.\")\n",
    "            continue\n",
    "\n",
    "        # Get frame dimensions\n",
    "        ih, iw, _ = frame.shape\n",
    "\n",
    "        # Convert frame to RGB for MediaPipe\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Face Detection\n",
    "        face_results = face_detection.process(rgb_frame)\n",
    "        face_bboxes = []\n",
    "\n",
    "        if face_results.detections:\n",
    "            for i, detection in enumerate(face_results.detections):\n",
    "                # Extract bounding box\n",
    "                bboxC = detection.location_data.relative_bounding_box\n",
    "                ih, iw, _ = frame.shape\n",
    "                x, y, w, h = (int(bboxC.xmin * iw), int(bboxC.ymin * ih),\n",
    "                              int(bboxC.width * iw), int(bboxC.height * ih))\n",
    "                face_bboxes.append((x, y, w, h))\n",
    "\n",
    "                # Draw bounding box around the face\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "                # Add label for each face\n",
    "                cv2.putText(frame, f\"Face {i+1}\", (x, y - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "        # Pose Detection\n",
    "        pose_results = pose.process(rgb_frame)\n",
    "        if pose_results.pose_landmarks:\n",
    "            filtered_landmarks = []\n",
    "            for i, lm in enumerate(pose_results.pose_landmarks.landmark):\n",
    "                x, y = int(lm.x * iw), int(lm.y * ih)\n",
    "                inside_face = any(fx <= x <= fx + fw and fy <= y <= fy + fh for fx, fy, fw, fh in face_bboxes)\n",
    "                if not inside_face:  # Only include landmarks outside face bounding boxes\n",
    "                    filtered_landmarks.append((x, y))\n",
    "\n",
    "            # Draw filtered pose landmarks\n",
    "            for x, y in filtered_landmarks:\n",
    "                cv2.circle(frame, (x, y), 3, (0, 0, 255), -1)\n",
    "\n",
    "\n",
    "        # Display the processed frame\n",
    "        cv2.imshow(\"MediaPipe YouTube Video Processing\", frame)\n",
    "\n",
    "        # Adjustable frame delay\n",
    "        time.sleep(frame_delay_ms / 1000.0)  # Convert ms to seconds\n",
    "\n",
    "        # Exit when 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(\"Exiting video processing.\")\n",
    "            break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734596265.413802 3508182 gl_context.cc:357] GL version: 2.1 (2.1 ATI-4.14.1), renderer: AMD Radeon Pro 555 OpenGL Engine\n",
      "W0000 00:00:1734596265.419068 3511817 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video URL: https://rr1---sn-jxopj-n5oe.googlevideo.com/videoplayback?expire=1734617868&ei=rNZjZ4y3A4yWsfIPyr3w2QI&ip=2607%3Af140%3A400%3A6b%3A8481%3Aaa15%3A119c%3Ac39f&id=o-AFtpSAoHUUj2X_nEuvUDEBJTYDYOW6ZtWTWpFkaX3dDc&itag=18&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&met=1734596268%2C&mh=KA&mm=31%2C29&mn=sn-jxopj-n5oe%2Csn-o097znse&ms=au%2Crdu&mv=m&mvi=1&pl=32&rms=au%2Cau&initcwndbps=4312500&bui=AfMhrI8OH-KxSNZ0tDqUW_7UVK_xXBKcBpaWy6FGqrSoAmBVQXmcIerS02jQxVQNL2Q-4bORx6Ok_5wH&vprv=1&svpuc=1&mime=video%2Fmp4&ns=0wKDSEkWV9J-LPo8ZdaX_2MQ&rqh=1&gir=yes&clen=124173805&ratebypass=yes&dur=2031.931&lmt=1733188644547912&mt=1734596001&fvip=2&fexp=51326932%2C51331020%2C51335594%2C51371293&c=MWEB&sefc=1&txp=4438434&n=O3wOY7x5bLucgQ&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cbui%2Cvprv%2Csvpuc%2Cmime%2Cns%2Crqh%2Cgir%2Cclen%2Cratebypass%2Cdur%2Clmt&sig=AJfQdSswRQIgdx9x9lNA9o5W4EyaISxwiVh1r2BYkEp2wNZSk7CiY3kCIQCdv9yLG42oqt9bTNgYNJgQX5iQVrNd1NTC0H-bni661Q%3D%3D&lsparams=met%2Cmh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Crms%2Cinitcwndbps&lsig=AGluJ3MwRAIgGT0K4NyiF0fSga6Th7IBs_x57JjvAkaqYnH830uLvqICID_hvyDBJFhXSrAuugpsmgQ7vyVIz8Jinu7B4l7RT4Ba\n",
      "Processing YouTube video. Press 'q' to quit.\n",
      "Exiting video processing.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 147\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# Save profiles to JSON\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprofiles.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 147\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241m.\u001b[39mdump(profiles, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProfiles saved to profiles.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "from deepface import DeepFace\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Function to fetch the direct video URL using yt-dlp\n",
    "def get_video_url(youtube_url):\n",
    "    ydl_opts = {\n",
    "        'quiet': True,\n",
    "        'format': 'best[ext=mp4]'\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(youtube_url, download=False)\n",
    "        return info['url']\n",
    "\n",
    "# Initialize MediaPipe solutions\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize Face Detection\n",
    "face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)\n",
    "\n",
    "# Profiles for tracking people\n",
    "profiles = {}\n",
    "max_inactive_frames = 30  # Maximum frames to keep a profile if not detected\n",
    "\n",
    "# Function to assign or update ID based on face embedding and spatial proximity\n",
    "def assign_id(embedding, bbox, profiles, frame_count, threshold=0.6, spatial_threshold=50):\n",
    "    best_match_id = None\n",
    "    best_similarity = float(\"inf\")\n",
    "    best_distance = float(\"inf\")\n",
    "\n",
    "    bbox_center = ((bbox[0] + bbox[2] / 2), (bbox[1] + bbox[3] / 2))\n",
    "\n",
    "    for profile_id, profile in profiles.items():\n",
    "        # Compare embedding similarity\n",
    "        similarity = np.linalg.norm(np.array(profile['face_embedding']) - np.array(embedding))\n",
    "        # Compare spatial proximity\n",
    "        profile_bbox = profile[\"bbox\"]\n",
    "        profile_center = ((profile_bbox[0] + profile_bbox[2] / 2), (profile_bbox[1] + profile_bbox[3] / 2))\n",
    "        spatial_distance = euclidean(profile_center, bbox_center)\n",
    "\n",
    "        # Find the best match\n",
    "        if similarity < threshold and spatial_distance < spatial_threshold:\n",
    "            if similarity < best_similarity or (similarity == best_similarity and spatial_distance < best_distance):\n",
    "                best_match_id = profile_id\n",
    "                best_similarity = similarity\n",
    "                best_distance = spatial_distance\n",
    "\n",
    "    if best_match_id is not None:\n",
    "        # Update the matched profile\n",
    "        profiles[best_match_id][\"bbox\"] = bbox\n",
    "        profiles[best_match_id][\"last_seen\"] = frame_count\n",
    "        return best_match_id\n",
    "    else:\n",
    "        # Create a new profile\n",
    "        new_id = len(profiles) + 1\n",
    "        profiles[new_id] = {\"face_embedding\": embedding, \"bbox\": bbox, \"last_seen\": frame_count}\n",
    "        return new_id\n",
    "\n",
    "# YouTube video URL\n",
    "youtube_url = \"https://www.youtube.com/watch?v=9D0WmzB5ovY\"  # Replace with your video URL\n",
    "\n",
    "# Fetch the video stream URL\n",
    "video_url = get_video_url(youtube_url)\n",
    "print(\"Video URL:\", video_url)\n",
    "\n",
    "# Open the video stream with OpenCV\n",
    "cap = cv2.VideoCapture(video_url)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open the YouTube video stream.\")\n",
    "else:\n",
    "    print(\"Processing YouTube video. Press 'q' to quit.\")\n",
    "\n",
    "    # Specify the start time (in seconds)\n",
    "    start_time = 30  # Start the video at 30 seconds\n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC, start_time * 1000)  # Jump to the start time\n",
    "\n",
    "    # Adjustable frame rate (delay in milliseconds)\n",
    "    frame_delay_ms = 100  # Adjust this value to control the frame rate\n",
    "    frame_count = 0  # Initialize frame counter\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"End of video or error reading the video stream.\")\n",
    "            break\n",
    "\n",
    "        # Increment frame count\n",
    "        frame_count += 1\n",
    "\n",
    "        # Convert the frame to RGB for MediaPipe\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect faces in the frame\n",
    "        face_results = face_detection.process(rgb_frame)\n",
    "        if face_results.detections:\n",
    "            for i, detection in enumerate(face_results.detections):\n",
    "                # Extract bounding box\n",
    "                bboxC = detection.location_data.relative_bounding_box\n",
    "                ih, iw, _ = frame.shape\n",
    "                x, y, w, h = (int(bboxC.xmin * iw), int(bboxC.ymin * ih),\n",
    "                              int(bboxC.width * iw), int(bboxC.height * ih))\n",
    "                bbox = (x, y, w, h)\n",
    "\n",
    "                # Extract face region\n",
    "                face_roi = rgb_frame[y:y+h, x:x+w]\n",
    "                if face_roi.size == 0:\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    # Generate face embedding\n",
    "                    embedding = DeepFace.represent(face_roi, model_name=\"Facenet\", enforce_detection=False)[0]['embedding']\n",
    "                    person_id = assign_id(embedding, bbox, profiles, frame_count)\n",
    "\n",
    "                    # Draw bounding box and label with embedding ID\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, f\"ID: {person_id}\", (x, y - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing face embedding in frame {frame_count}: {e}\")\n",
    "\n",
    "        # Remove stale profiles\n",
    "        profiles = {k: v for k, v in profiles.items() if frame_count - v[\"last_seen\"] <= max_inactive_frames}\n",
    "\n",
    "        # Display the processed frame\n",
    "        cv2.imshow(\"MediaPipe YouTube Video Processing\", frame)\n",
    "\n",
    "        # Adjustable frame delay\n",
    "        time.sleep(frame_delay_ms / 1000.0)  # Convert ms to seconds\n",
    "\n",
    "        # Exit when 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(\"Exiting video processing.\")\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save profiles to JSON\n",
    "with open(\"profiles.json\", \"w\") as f:\n",
    "    json.dump(profiles, f, indent=4)\n",
    "print(f\"Profiles saved to profiles.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video URL: https://rr2---sn-o097znsr.googlevideo.com/videoplayback?expire=1733935790&ei=Tm5ZZ8OCHvr-sfIP1OPhoAg&ip=2601%3A644%3A601%3Afa0%3A18f1%3A6d9c%3A9455%3Ae968&id=o-AM0VWy9id_RhIja_CuAX_7jCOsmuB3nF0M_O12ZHnnTH&itag=18&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&met=1733914190%2C&mh=Vq&mm=31%2C29&mn=sn-o097znsr%2Csn-n4v7sns7&ms=au%2Crdu&mv=m&mvi=2&pl=34&rms=au%2Cau&initcwndbps=3915000&bui=AQn3pFQKhi7MVAR6il70JWVEwJTRLPZJ7nzHT55pqdE6sdGYDy3fT88Js2ixpJEj8o83imVFwTnhby9Q&vprv=1&svpuc=1&mime=video%2Fmp4&ns=dgnEsjCi-frwcKg6mSObwzwQ&rqh=1&gir=yes&clen=36612911&ratebypass=yes&dur=398.593&lmt=1733879672190924&mt=1733913906&fvip=3&fexp=51326932%2C51331020%2C51335594%2C51347747&c=MWEB&sefc=1&txp=5538434&n=jbygYr9NxynRtw&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cbui%2Cvprv%2Csvpuc%2Cmime%2Cns%2Crqh%2Cgir%2Cclen%2Cratebypass%2Cdur%2Clmt&sig=AJfQdSswRQIgR_sLg4GdoV2OPdKEWhxKh-0u7jr7-NyGlLR3-mI-5a4CIQCMCLTi1P8C5kClsDZoxqTwkw4zeYhfluOoJaAbPTohlA%3D%3D&lsparams=met%2Cmh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Crms%2Cinitcwndbps&lsig=AGluJ3MwRgIhALgf6xqIvH2_zJFtPeRe5B3pKHJ1_9PBscS31k00XqeSAiEAnM93YZVNr-yM9FGS5GMcczeju1avkIGr7LL3n5C5ztY%3D\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 32\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     30\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYouTube Video\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame)\n\u001b[0;32m---> 32\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     33\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     35\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#old code that just streams without mediapipe facial recognition\n",
    "# Get the direct video URL\n",
    "import yt_dlp\n",
    "import cv2\n",
    "\n",
    "def get_video_url(youtube_url):\n",
    "    ydl_opts = {\n",
    "        'quiet': True,\n",
    "        'format': 'best[ext=mp4]'\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(youtube_url, download=False)\n",
    "        return info['url']\n",
    "\n",
    "# Get the direct video URL\n",
    "youtube_url = \"https://www.youtube.com/watch?v=m34ZKJNyxac\"\n",
    "video_url = get_video_url(youtube_url)\n",
    "print(\"Video URL:\", video_url)\n",
    "\n",
    "# Open video stream with OpenCV\n",
    "cap = cv2.VideoCapture(video_url)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video stream.\")\n",
    "else:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        cv2.imshow(\"YouTube Video\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "video_url = get_video_url(youtube_url)\n",
    "print(\"Video URL:\", video_url)\n",
    "\n",
    "# Open video stream with OpenCV\n",
    "cap = cv2.VideoCapture(video_url)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video stream.\")\n",
    "else:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        cv2.imshow(\"YouTube Video\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todo, need to add cookies for age restricted content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "office",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
